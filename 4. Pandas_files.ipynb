{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Основы работы с функцией read_csv()**\n",
    "\n",
    "Pandas предоставляет простой и удобный интерфейс для работы с табличными данными. Одним из наиболее распространенных форматов данных, с которыми мы сталкиваемся, являются CSV-файлы (Comma-Separated Values), где данные представлены в виде таблицы, разделенной запятыми.  Для этого в Pandas есть функция read_csv(), которую мы будем использовать. Она позволяет загружать данные из файлов CSV и создавать объекты DataFrame, основной структуры данных в Pandas.\n",
    "\n",
    "Синтаксис:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv') # 'data.csv' - путь к файлу."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По умолчанию Pandas сам определяет заголовки (параметр header='infer'), если же они определены неверно, можно указать их явно через параметр header (header=n, где n - номер строки). Если нужно, чтобы Pandas вообще не пытался считать заголовок, надо указать значение параметра header=None.\n",
    "\n",
    "Еще одним важным моментом чтения файлов CSV является указание разделителя столбцов. По умолчанию Pandas ожидает, что столбцы будут разделены запятыми, но иногда файлы CSV могут использовать другие разделители, такие как табуляция или точка с запятой. В таком случае мы можем указать разделитель с помощью **параметра sep**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Параметр encoding** в функции read_csv() в библиотеке Pandas используется для указания кодировки, используемой при чтении файла CSV.\n",
    "\n",
    "Кодировка определяет способ представления символов и текста в файле. Различные языки и регионы могут использовать различные кодировки, и если файл CSV содержит текст, записанный в определенной кодировке, необходимо указать соответствующую кодировку при чтении файла.\n",
    "\n",
    "Параметр encoding принимает строку, содержащую имя кодировки. Некоторые распространенные кодировки, которые могут быть использованы, включают:\n",
    "* `utf-8`: Самая распространенная кодировка для текстовых файлов. Она поддерживает широкий набор символов и является стандартом веба.\n",
    "* `latin-1`: Также известная как ISO-8859-1, она поддерживает большинство европейских языков.\n",
    "* `utf-16`: Кодировка, использующая 16-битное представление символов. Часто используется для мультиязычных данных.\n",
    "* `cp1252`: Расширение кодировки latin-1 с дополнительными символами и символами Windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas автоматически определяет кодировку исходя из того, какая кодировка используется в системе (в подавляющем большинстве случаев utf-8)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Параметр names** в функции read_csv() в библиотеке Pandas используется для явного указания имен столбцов при чтении файла CSV.\n",
    "\n",
    "По умолчанию Pandas ожидает, что первая строка в файле CSV содержит заголовки столбцов. Однако, иногда файлы CSV могут не содержать заголовков, или заголовки могут быть некорректными или неполными. В таких случаях мы можем использовать параметр names для явного указания имен столбцов при чтении файла CSV.\n",
    "\n",
    "Параметр names принимает список или массив строк, где каждая строка представляет собой имя столбца. Количество элементов в списке names должно соответствовать количеству столбцов в файле CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv', names=['Имя', 'Возраст', 'Город'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Использование параметра names особенно полезно при работе с файлами CSV, которые не содержат заголовков или имеют некорректные заголовки. Это позволяет явно задавать имена столбцов и обеспечивает точное соответствие данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Параметр index_col** в функции read_csv() в библиотеке Pandas используется для указания столбца, который следует использовать в качестве индекса (метки строк) при чтении файла CSV.\n",
    "\n",
    "По умолчанию Pandas создает числовой индекс (0, 1, 2, и так далее) для каждой строки DataFrame. Однако, в некоторых случаях удобно использовать значения определенного столбца в качестве индекса, особенно если эти значения являются уникальными и идентифицируют каждую строку набора данных.\n",
    "\n",
    "Параметр index_col может принимать различные значения:\n",
    "\n",
    "* `Целое число`: Если указать целое число, то столбец с соответствующим индексом будет использован в качестве индекса. Например, index_col=0 означает, что первый столбец будет использован в качестве индекса.\n",
    "* `Имя столбца`: Если указать имя столбца (строку), то столбец с этим именем будет использован в качестве индекса. Например, index_col='ID' означает, что столбец с именем \"ID\" будет использован в качестве индекса.\n",
    "* `Список столбцов`: Если указать список столбцов (с целыми числами или именами столбцов), то Pandas будет использовать комбинацию значений из указанных столбцов в качестве составного индекса (мультииндекса)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv', index_col='ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Параметр skiprows** в функции read_csv() в библиотеке Pandas используется для пропуска определенного числа строк при чтении файла CSV.\n",
    "\n",
    "Иногда файлы CSV могут содержать строковые заголовки или метаинформацию, которые не являются частью набора данных, и нам необходимо пропустить эти строки при загрузке данных. В таких случаях мы можем использовать параметр skiprows для указания количества строк, которые следует пропустить.\n",
    "\n",
    "Параметр skiprows принимает целое число или список целых чисел, представляющих номера строк, которые следует пропустить. Нумерация строк начинается с 0, то есть первая строка имеет номер 0, вторая - 1 и так далее. Можно указывать несколько строк для пропуска, передавая их в виде списка."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv', skiprows=1) # пропустится первая строка\n",
    "df = pd.read_csv('data.csv', skiprows=2) # пропустятся первые две строки\n",
    "df = pd.read_csv('data.csv', skiprows=[0, 2]) # пропустятся первая и третья строки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Параметр skipfooter** в функции read_csv() в библиотеке Pandas используется для пропуска определенного числа строк в конце файла CSV при чтении.\n",
    "\n",
    "В некоторых случаях файлы CSV могут содержать строковые или метаданные строки в конце файла, которые не являются частью набора данных и не должны быть загружены. В таких случаях мы можем использовать параметр skipfooter для указания количества строк, которые следует пропустить в конце файла.\n",
    "\n",
    "Параметр skipfooter принимает целое число, которое указывает количество строк, которые следует пропустить. При чтении файла CSV Pandas будет пропускать указанное количество строк в конце файла."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv', skipfooter=2) # пропустятся последние две строки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Параметр skipfooter также имеет дополнительное требование: при использовании этого параметра Pandas не будет использовать быстрый алгоритм чтения CSV-файла, и это может сказаться на производительности при чтении больших файлов. Поэтому рекомендуется быть осторожным при использовании skipfooter с крупными файлами данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Параметр na_values** в функции read_csv() в библиотеке Pandas используется для указания значений, которые следует рассматривать как пропущенные данные (NA, NaN, null) при чтении файла CSV.\n",
    "\n",
    "В файле CSV могут быть явно указанные значения, которые представляют собой пропущенные или отсутствующие данные. Эти значения могут быть обозначены различными способами, например, как \"NA\", \"NaN\", \"null\", или любым другим пользовательским значением.\n",
    "\n",
    "Параметр na_values позволяет указать такие значения, чтобы Pandas мог корректно распознать и обрабатывать их как пропущенные данные при чтении файла CSV. Параметр na_values может принимать различные форматы:\n",
    "\n",
    "* `Строка`: Можно передать строку, содержащую одно или несколько значений, разделенных запятыми или пробелами. Например, na_values='NA' или na_values='NA, --, NULL'.\n",
    "* `Список`: Можно передать список значений, которые следует рассматривать как пропущенные. Например, na_values=['NA', '--', 'NULL'].\n",
    "* `Словарь`: Можно передать словарь, где ключами являются имена столбцов, а значениями - значения, которые следует рассматривать как пропущенные для соответствующих столбцов. Например, na_values={'column1': ['NA', '--'], 'column2': ['NULL']}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv', na_values='NA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом примере все значения \"NA\" в файле CSV будут рассматриваться как пропущенные данные и будут заменены на NaN в объекте DataFrame df."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Парсинг дат с помощью функции read_csv()**\n",
    "\n",
    "Параметр функции read_csv(), позволяющий парсить даты - parse_dates.\n",
    "\n",
    "Параметр parse_dates может принимать несколько значений:\n",
    "\n",
    "1. Дата в определенной колонке.\n",
    "2. Дата в нескольких колонках.\n",
    "3. Дата в нестандартном формате."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# пример парсинга даты в определённой колонке\n",
    "df = pd.read_csv(\"file.csv\", parse_dates=[\"date\"])\n",
    "\n",
    "# пример парсинга даты в нескольких колонках\n",
    "df = pd.read_csv(\"file.csv\", parse_dates=[\"date\", \"time\"])\n",
    "\n",
    "# пример парсинга даты в нестандартном формате (год-месяц-день-час-минута-секунда)\n",
    "df = pd.read_csv(\"file.csv\", parse_dates=[\"date\"], \n",
    "     date_parser=lambda x: datetime.strptime(x, '%Y-%m-%d-%H-%M-%S'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция pd.to_datetime() и функция datetime.strptime() модуля datetime, могут использоваться в качестве фиксированных обработчиков дат в параметре date_parser.\n",
    "\n",
    "Подробнее про работу этих функций в файле 'extra'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ещё пример. Допустим, есть csv-файл, содержащий даты в формате 'dd-mm-yyyy'\n",
    "# чтобы прочитать этот файл с помощью параметра date_parser, можно использовать datetime.strptime() и создать функцию, которая принимает дату как строку и возвращает объект datetime\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "def custom_date_parser(date_str): \n",
    "    return datetime.strptime(date_str, '%d-%m-%Y') \n",
    "\n",
    "df = pd.read_csv('data.csv', parse_dates=['date'],date_parser=custom_date_parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# пример использования функции pd.to_datetime() для парсинга даты из csv_файла\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data.csv') \n",
    "df['date'] = pd.to_datetime(df['date'], format='%d-%m-%Y')\n",
    "\n",
    "print(df['date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Чтение больших файлов csv**\n",
    "\n",
    "При работе с большими CSV-файлами может возникнуть проблема из-за ограничений по памяти. С помощью Pandas можно обрабатывать большие файлы, не загружая их полностью в память."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Метод pd.read_csv() с параметром chunksize**\n",
    "\n",
    "Один из способов снижения использования нагрузки на память при работе с большими данными - загрузка и обработка данных по частям. Для этого можно использовать вызов функции pd.read_csv() с параметром chunksize. Параметр chunksize позволяет считывать данные из CSV-файла кусками (chunks) заданного размера. Это может быть особенно полезно, когда нужно обработать огромный по по размеру файл, но ресурсы оперативной памяти ограничены."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# пример синтаксиса и работы параметра chunksize\n",
    "import pandas as pd\n",
    "\n",
    "filename = \"large_file.csv\" \n",
    "chunksize = 1000 # Задаем размер части (куска) \n",
    "# Считываем куски данных из файла \n",
    "chunks = pd.read_csv(filename, chunksize=chunksize) \n",
    "# Обрабатываем каждый кусок \n",
    "for chunk in chunks: \n",
    "    # Здесь можно выполнять любые операции обработки данных \n",
    "    print(chunk.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном случае chunks, возвращаемый функцией read_csv() является итератором (или генератором), который разбивает весь набор данных из файла, который считывается, на равные части. Каждая часть имеет заданный размер chunksize, что значительно упрощает обработку больших данных с помощью Pandas, так как не нужно загружать весь набор данных в оперативную память за один раз. Каждый раз, когда происходит итерация по объекту chunks, получается часть данных размером chunksize (или меньше, если конец данных) в виде DataFrame. С этим фрагментом данных можно выполнять различные операции, обрабатывая его частями, чтобы работать с большими файлами на слабых компьютерах или при ограниченной доступности памяти."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Оптимизация использования памяти**\n",
    "\n",
    "Кроме использования chunksize и iterator, можно оптимизировать потребление памяти при чтении больших CSV-файлов, задавая специфические преобразования и типы данных. Как например, конвертация дат и времени с помощью параметра parse_dates. Это преобразует строковые представления дат и времени в соответствующие объекты `datetime`.\n",
    "\n",
    "Также можно явно задавать типы данных столбцов с помощью параметра dtype. Это особенно полезно для столбцов с категориальными данными или столбцов с большим количеством нулевых значений. Также параметр dtype бывает полезен при большом количестве пропусков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# пример синтаксиса явного задания типов\n",
    "pd.read_csv(\"large_file.csv\", dtype={\"category_column\": \"category\", \"nullable_column\": \"Int64\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Запись данных в файл с помощью функции to_csv()**\n",
    "\n",
    "Функция to_csv в библиотеке Pandas используется для записи данных из объекта DataFrame в файл формата CSV. Она имеет множество параметров, позволяющих настраивать режим записи в файл, включая разделитель, наличие индексов и заголовков, а также многое другое.\n",
    "\n",
    "Основные параметры:\n",
    "- `path_or_buf`: путь к сохраняемому файлу или файлоподобному объекту (file-like), если хотите сохранять данные в буфер памяти\n",
    "- `sep`: разделитель для значений в CSV-файле. По умолчанию ','.\n",
    "- `header`: указывает выводить ли заголовки колонок DataFrame в файл CSV. Если True, заголовок будет выведен. Если False, заголовок не будет выведен. Если передана последовательность строк, то он будет использован в качестве заголовков столбцов вместо отображения названий столбцов DataFrame. По умолчанию True.\n",
    "- `index`: указывает выводить ли индексы в файл CSV. Если True, индексы будут выведены. Если False, индексы не будут выведены. По умолчанию True.\n",
    "- `mode`: режим записи файла, поддерживаемые значения - 'w' (замена), 'a' (дозапись), 'x' (запись в новый файл). По умолчанию 'w'.\n",
    "- `encoding`: кодировка выходного файла. По умолчанию 'utf-8'.\n",
    "- `line_terminator`: строка завершения записи. По умолчанию, как на вашей системе '\\n'.\n",
    "- `date_format`: формат даты и времени для записи, например, '%Y-%m-%d' для год-месяц-день. Если не указан, будут использоваться настройки базы данных и UTC для преобразования дат и времени.\n",
    "- `compression`: Этот параметр позволяет выбрать тип сжатия, например, 'gzip' или 'bz2'. Вышеупомянутые параметры могут быть использованы, чтобы настроить содержимое файла CSV при сохранении DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# пример экспорта в csv\n",
    "import pandas as pd \n",
    "\n",
    "data = { 'Name': ['Alice', 'Bob', 'Carol'], 'Age': [30, 25, 40], \n",
    "         'Height': [155.2, 175.5, 163.8], 'Weight': [60.5, 80.2, 65.7] } \n",
    "df = pd.DataFrame(data) \n",
    "\n",
    "df.to_csv('my_data.csv', index=False) # сохранится в открытую папку в visual code studio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name,Age,Height,Weight\n",
      "Alice,30,155.2,60.5\n",
      "Bob,25,175.5,80.2\n",
      "Carol,40,163.8,65.7\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# пример экспорта в буфер обмена\n",
    "import io \n",
    "import pandas as pd\n",
    "\n",
    "data = { 'Name': ['Alice', 'Bob', 'Carol'], 'Age': [30, 25, 40], \n",
    "         'Height': [155.2, 175.5, 163.8], 'Weight': [60.5, 80.2, 65.7] }\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "buffer = io.StringIO()\n",
    "df.to_csv(buffer, index=False)\n",
    "\n",
    "print(buffer.getvalue()) # и скопировать отсюда"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Функция pandas.read_table() и ее возможности**\n",
    "\n",
    "Функция pandas.read_table позволяет читать данные из различных форматов файлов. Она может работать с текстовыми файлами, такими как CSV, TSV, TXT, а также с файлами Excel, JSON, HTML и другими.\n",
    "\n",
    "*TSV (Tab-Separated Values) - это формат для хранения табличных данных, в котором столбцы разделены символами табуляции (Tabs), а строки - символами перехода на новую строку. TSV-файлы часто используются для экспорта и импорта данных из различных программ, в частности, они являются стандартным форматом данных в электронных таблицах программ Microsoft Excel и Google Sheets. TSV-файлы подобны CSV-файлам, но вместо запятых в качестве разделителей используется символ табуляции. Использование символа табуляции вместо запятой позволяет создавать более структурированные и читаемые табличные данные, так как обычно запятые могут использоваться внутри значений ячеек в качестве разделителей различных значений.*\n",
    "\n",
    "\n",
    "В целом все форматы файлов, которые можно использовать для хранения структурированных данных, могут быть прочитаны с помощью pandas.read_table.\n",
    "\n",
    "Однако, для корректного парсинга файла с помощью этой функции следует учитывать несколько важных требований:\n",
    "\n",
    "1. Файл должен быть в текстовом формате.\n",
    "2. Файл должен содержать структурированные данные, представленные в виде таблицы.\n",
    "3. Данные в файле должны быть разделены определенным символом - разделителем (обычно символ табуляции, запятая или точка с запятой).\n",
    "4. Для корректного отображения и анализа данных, файл должен содержать заголовок или имена столбцов.\n",
    "5. Файл должен быть легко читаем в буфер памяти, иными словами, размер файла не должен быть слишком большим для системы.\n",
    "\n",
    "Функция pandas.read_table используется для чтения данных из текстовых файлов в формате таблицы, таких как CSV или TSV. Ниже приводятся основные параметры этой функции:\n",
    "\n",
    "- `filepath_or_buffer`: путь к файлу или объекту, содержащему данные для чтения. Этот параметр обязателен.\n",
    "- `sep:` разделитель столбцов в файле. По умолчанию это ‘\\t’ - символ табуляции.\n",
    "- `delimiter`: аналогичен предыдущему параметру.\n",
    "- `header`: номер строки, содержащей имена столбцов. Если не задан, то имена автоматически будут сгенерированы.\n",
    "- `index_col`: номер столбца, который будет использован в качестве индекса таблицы. Если не задан, то индекс будет сгенерирован автоматически.\n",
    "- `usecols`: список столбцов, которые нужно загрузить в таблицу. Если не задан, то загружаются все столбцы.\n",
    "- `dtype`: словарь, указывающий тип данных для каждого столбца. Если не задан, то pandas попытается определить типы данных автоматически.\n",
    "- `na_values`: список значений, которые следует считать отсутствующими в данных.\n",
    "- `parse_dates`: список столбцов, содержащих даты, которые должны быть преобразованы в тип данных pandas datetime.\n",
    "- `skiprows`: количество строк, которые нужно пропустить в начале файла.\n",
    "- `nrows`: количество строк, которые нужно загрузить из файла.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Загрузка JSON файлов в Pandas**\n",
    "\n",
    "JSON (JavaScript Object Notation) - формат обмена данными, основанный на JavaScript. Он представляет собой легкий, текстовый формат, который используется для хранения и передачи данных между клиентом и сервером. Файлы в формате JSON имеют расширение - .json. JSON файлы имеют простую и понятную структуру, которая состоит из двух основных элементов: пар ключ-значение и массивов. Пары ключ-значение представляют собой объекты, которые содержат имена и значения. Массивы представляют собой упорядоченные наборы значений, разделенные запятыми. Ключ-значение представлено в формате:  \"ключ\": \"значение\" (примерно аналогично словарю в Python).\n",
    "\n",
    "Массивы в JSON представлены в формате: \n",
    "\n",
    "`{ \"fruits\": [\"apple\", \"banana\", \"orange\"] }`\n",
    "\n",
    "Это представляет объект fruits, который является массивом из трех элементов: \"apple\", \"banana\", \"orange\". JSON используется практически везде, где нужно обмениваться данными, включая web-приложения, сервисы, базы данных, мобильные приложения и другие программы. В Python для работы с JSON используется стандартная библиотека json. С помощью нее можно конвертировать данные в формате JSON в python объекты и наоборот.\n",
    "\n",
    "Pandas для загрузки данных из JSON файлов предоставляет функцию read_json(). Эта функция загружает данные из файла в формате JSON и создает объект DataFrame. Метод принимает следующие параметры:\n",
    "\n",
    "- `path_or_buf`: имя файла или фалоподобного объекта (например URL-адрес файла из сети Интернет), из которого нужно загрузить данные.\n",
    "- `orient`: определяет ориентацию таблицы (Указывает ожидаемый формата строки JSON). Возможные значения, например: 'split', 'records', 'index', 'columns', 'values'. По умолчанию ориентация определяется автоматически.\n",
    "- `typ`: определяет тип объекта, который нужно создать. Может принимать значения: 'frame', 'series'.\n",
    "- `convert_dates`: определяет нужно ли конвертировать значения в формат datetime.\n",
    "\n",
    "Использование параметра **orient**:\n",
    "- `'columns'`: В этой ориентации каждый ключ верхнего уровня в JSON-файле соответствует столбцу в DataFrame, а значения - это данные в соответствующих столбцах.\n",
    "- `'index'`: В этой ориентации каждый ключ верхнего уровня в JSON-файле соответствует индексу в DataFrame, а значения - это данные в соответствующих строках.\n",
    "- `'records'`: В этой ориентации каждый объект в JSON-файле представляет собой отдельную запись (строку) в DataFrame.\n",
    "- `'split'`: В этой ориентации данные разделены на отдельные части.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Функция pandas.read_html()**\n",
    "\n",
    "HTML (HyperText Markup Language) - это язык разметки, используемый для создания веб-страниц и их структурирования. Он состоит из набора тегов (элементов), которые определяют структуру и содержимое веб-страницы.\n",
    "\n",
    "Основная цель HTML состоит в том, чтобы описывать содержимое веб-страницы, такое как текст, изображения, ссылки, таблицы и другие элементы. Когда браузер открывает HTML-страницу, он интерпретирует и отображает содержимое согласно указанным тегам.\n",
    "\n",
    "основные компоненты:\n",
    "\n",
    "* `<!DOCTYPE html>`: Объявление типа документа, в данном случае HTML5.\n",
    "* `<html>`: Корневой элемент, обозначающий начало и конец HTML-документа.\n",
    "* `<head>`: Содержит метаданные о веб-странице, такие как заголовок (`<title>`) и подключение стилей или скриптов.\n",
    "* `<body>`: Определяет содержимое веб-страницы, отображаемое в браузере.\n",
    "* `<h1>`: Заголовок первого уровня.\n",
    "* `<p>`: Параграф с текстом.\n",
    "* `<img>`: Изображение.\n",
    "* `<a>`: Гиперссылка (ссылка).\n",
    "* `<table>`: Таблица, содержащая строки (`<tr>`) и ячейки (`<td>`).\n",
    "\n",
    "HTML предоставляет широкий набор тегов для создания различных элементов на веб-странице. Каждый тег имеет свое собственное значение и атрибуты, которые могут использоваться для настройки внешнего вида или поведения элемента.\n",
    "\n",
    "Функция read_html() из библиотеки Pandas предназначена для загрузки данных таблиц из HTML-файлов, HTML-страниц или HTML-кода и преобразования их в объекты DataFrame.\n",
    "\n",
    "Функция read_html() из библиотеки Pandas использует парсеры HTML (такие как lxml или beautifulsoup4), чтобы анализировать HTML-код и находить таблицы.\n",
    "\n",
    "Внутри read_html() происходит следующий процесс:\n",
    "\n",
    "1. Функция получает HTML-код из указанного источника (файл, URL или HTML-строка).\n",
    "2. Используя выбранный парсер (по умолчанию это lxml), read_html() анализирует HTML-код и создает объекты, представляющие структуру документа.\n",
    "3. Затем read_html() применяет соответствующие правила и эвристики для определения, какие части HTML-кода считать таблицами.\n",
    "4. Функция ищет теги `<table>` в HTML-коде и анализирует их содержимое, чтобы создать объекты DataFrame, представляющие таблицы.\n",
    "5. Если в HTML-коде присутствует несколько таблиц, read_html() возвращает список объектов DataFrame, каждый из которых соответствует одной таблице.\n",
    "\n",
    "Точность и эффективность работы read_html() может зависеть от структуры и качества HTML-кода. В некоторых случаях, если HTML-код не является хорошо организованным или имеет неточности, может потребоваться дополнительная обработка данных после загрузки таблицы с помощью read_html().\n",
    "\n",
    "**Парсеры HTML** - это программные инструменты, которые анализируют HTML-код и позволяют извлекать данные из него. Они разбирают HTML-документ и создают структурированное объектное представление его содержимого, что облегчает поиск, извлечение и обработку данных.\n",
    "\n",
    "HTML-код представляет собой набор тегов и текстового содержимого, описывающего структуру и содержание веб-страницы. Парсеры HTML сканируют этот код, идентифицируют различные элементы и атрибуты, а затем создают объекты, представляющие эти элементы. Это позволяет программам обрабатывать и взаимодействовать с HTML-кодом.\n",
    "\n",
    "Некоторые из популярных парсеров HTML в языке программирования Python:\n",
    "\n",
    "1. `lxml`: Это быстрый и гибкий парсер, основанный на библиотеке C для обработки XML и HTML. Он предоставляет API для поиска и извлечения данных из HTML-кода, а также для внесения изменений в структуру документа. Библиотека lxml широко используется в Python для парсинга HTML-кода.\n",
    "2. `Beautiful Soup`: Это библиотека Python, предназначенная для извлечения данных из HTML и XML. Она предоставляет простой и интуитивно понятный API, который позволяет выполнять поиск и манипулирование элементами HTML-кода. Beautiful Soup поддерживает разные парсеры, включая lxml, html.parser, html5lib и другие.\n",
    "3. `html.parser`: Это встроенный в стандартную библиотеку Python парсер HTML. Он реализован на языке Python и обеспечивает базовые функции для анализа и обработки HTML-кода. В отличие от некоторых других парсеров, html.parser не требует дополнительной установки.\n",
    "\n",
    "Каждый парсер имеет свои особенности и возможности. Они предоставляют API для поиска, извлечения и манипулирования элементами HTML-кода.\n",
    "\n",
    "**Для использования функции read_html() из библиотеки Pandas требуется установить библиотеки lxml и beautifulsoup4.**\n",
    "\n",
    "Параметры функции read_html():\n",
    "* `io`: Обязательный параметр. Может быть путем к HTML-файлу, URL-адресом или объектом, содержащим HTML-код.\n",
    "* `match`: По умолчанию \".+\". Определяет регулярное выражение для поиска таблиц в HTML-коде. По умолчанию найдутся все таблицы.\n",
    "* `flavor`: По умолчанию None. Указывает на используемую библиотеку для парсинга HTML. Допустимые значения: 'bs4' (BeautifulSoup 4) и 'lxml'.\n",
    "* `header`: По умолчанию None. Указывает номер строки для использования в качестве заголовков столбцов. Если не указано, заголовки будут автоматически определены.\n",
    "* `index_col`: По умолчанию None. Указывает номер столбца для использования в качестве индекса строк. Если не указано, индексы строк будут автоматически определены.\n",
    "* `skiprows`: По умолчанию None. Указывает номера строк для пропуска при загрузке таблицы.\n",
    "* `attrs`: По умолчанию None. Список атрибутов HTML-тега для использования в качестве фильтра при поиске таблиц.\n",
    "* `parse_dates`: По умолчанию False. Указывает, нужно ли парсить значения столбцов как даты.\n",
    "* `thousands`: По умолчанию ','. Определяет разделитель тысячных.\n",
    "* `encoding`: По умолчанию None. Указывает кодировку файла.\n",
    "* `decimal`: По умолчанию '.'. Определяет символ десятичного разделителя.\n",
    "* `converters`: По умолчанию None. Словарь, который определяет пользовательские функции преобразования для столбцов.\n",
    "* `na_values`: По умолчанию None. Список значений, которые должны быть распознаны как пропущенные значения.\n",
    "* `keep_default_na`: По умолчанию True. Определяет, должны ли использоваться значения по умолчанию для распознавания пропущенных значений.\n",
    "* `displayed_only`: По умолчанию True. Указывает, следует ли извлекать только видимые данные таблицы.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# пример загрузки данных из локального html-файла\n",
    "import pandas as pd\n",
    "\n",
    "table_data = pd.read_html('путь_к_файлу.html')\n",
    "data_frame = table_data[0]\n",
    "\n",
    "print(data_frame.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# пример загрузки данных из HTML-страницы по URL-адресу\n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://www.example.com/table.html'\n",
    "table_data = pd.read_html(url)\n",
    "data_frame = table_data[0]\n",
    "\n",
    "print(data_frame.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# пример загрузки данных с использованием фильтра атрибутов HTML-тега\n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://www.example.com/table.html'\n",
    "table_data = pd.read_html(url, attrs={'class': 'table-class'})\n",
    "data_frame = table_data[0]\n",
    "\n",
    "print(data_frame.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# пример загрузки данных с парсингом дат и пользовательскими функциями преобразования\n",
    "import pandas as pd\n",
    "\n",
    "table_data = pd.read_html('путь_к_файлу.html', parse_dates=True, converters={'column_name': pd.to_numeric})\n",
    "data_frame = table_data[0]\n",
    "\n",
    "print(data_frame.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
